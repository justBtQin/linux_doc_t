# 关于 Linux 2.5 中通用块层重写的注释

=====================================================

编写日期：2002 年 1 月 15 日

作者：Jens Axboe <jens.axboe@oracle.com>，Suparna Bhattacharya <suparna@in.ibm.com>

最新更新日期：2002 年 5 月 2 日

2003 年 9 月：更新了 I/O 调度器部分

作者：Nick Piggin <npiggin@kernel.dk>

引言：

这些是一些在 bio 重写背景下描述 2.5 块层某些方面的注释。其目的是揭示一些关键变化以及这些变化背后的基本原理。

请将更正和建议发送至 suparna@in.ibm.com。

# 致谢：

---------

2.5 bio 重写：

Jens Axboe <jens.axboe@oracle.com>

通用块层重新设计的许多方面是通过讨论、先前的补丁以及几个人的集体经验推动和发展而来的。有关一些相关参考的列表，请参见第 8 节和第 9 节。

以下人员帮助审查了本文档的评论和输入：

Christoph Hellwig <hch@infradead.org>

Arjan van de Ven <arjanv@redhat.com>

Randy Dunlap <rdunlap@xenotime.net>

Andre Hedrick <andre@linux-ide.org>

以下人员在 bio 补丁仍在进行中时帮助进行了修复/贡献：

David S. Miller <davem@redhat.com>

# 内容描述：

------------------------

1. 针对各种需求调整逻辑的范围

  1.1 根据设备或低级驱动程序功能进行调整

    - 每个队列的参数

    - 高内存 I/O 支持

    - I/O 调度器模块化

  1.2 根据高级要求/功能进行调整

    1.2.1 请求优先级/延迟

  1.3 直接访问/绕过底层以进行诊断和特殊设备操作

    1.3.1 预构建命令

2. 新的灵活且通用但简约的 I/O 结构或描述符（而不是在 I/O 层使用缓冲区头）

  2.1 解决的需求/目标

  2.2 详细的 bio 结构（多页 I/O 单元）

  2.3 请求结构的变化

3. 使用 bios

  3.1 设置/拆除（分配、拆分）

  3.2 通用 bio 辅助例程

    3.2.1 遍历请求中的段和完成单元

    3.2.2 设置 DMA 分散列表

    3.2.3 I/O 完成

    3.2.4 对不解释 bios 的驱动程序的影响（不处理多个段）

    3.2.5 请求命令标记

  3.3 I/O 提交

4. I/O 调度器

5. 与可扩展性相关的更改

  5.1 细粒度锁定：删除 io_request_lock

  5.2 为向 64 位 sector_t 过渡做准备

6. 其他更改/影响

  6.1 分区重新映射由通用块层处理

7. 关于旧驱动程序迁移的一些提示

8. 先前/相关/受影响的补丁/想法列表

9. 其他参考/讨论线程

---------------------------------------------------------------------------

# Bio 注释

--------

让我们在如何满足块层的一些总体目标的背景下讨论这些变化。

1. 调整通用逻辑以满足各种需求的范围

块层设计支持可适应的抽象，以处理常见的处理，并能够根据设备的性质和调用者的要求在适当的程度上调整逻辑。重写的目标之一是增加可调整性的程度，并使高级代码能够最大程度地利用底层设备/驱动程序的功能，以获得更好的 I/O 性能。这在硬件能力不断提高以及旨在利用这些能力的应用程序/中间件软件的背景下尤为重要。

## 1.1 根据低级设备/驱动程序功能进行调整

具有大型内置缓存、智能 I/O 调度优化、高内存 DMA 支持等的复杂设备可能会发现一些通用处理是一种开销，而对于能力较弱的设备，通用功能对于性能或正确性原因是必不可少的。应该在通用块层使用设备的一些功能或参数的知识，代表驱动程序做出正确的决策。

如何实现这一点？

每个队列的调整：

i. 驱动程序导出给通用层的每个队列的限制/值

通用 I/O 调度器逻辑使用的各种参数在每个队列级别设置（例如，最大请求大小、分散-聚集列表中的最大段数、硬扇区大小）

一些以前作为全局数组（按主/次索引）可用的参数现在直接与队列相关联。其中一些可能在将来移入块设备结构中。一些特征已合并到队列标志字段中，而不是作为单独的字段本身。有 blk_queue_xxx 函数来设置参数，而不是直接更新字段

一些新的队列属性设置：

```
	blk_queue_bounce_limit(q, u64 dma_address)
		启用对高内存页的 I/O，dma_address 为限制。无高内存默认值。
	blk_queue_max_sectors(q, max_sectors)
		设置两个限制请求大小的变量。
		- 请求队列的 max_sectors，以 512 字节扇区为单位的软大小，可以由核心内核动态更改。
		- 请求队列的 max_hw_sectors，这是一个硬限制，反映驱动程序可以处理的以 512 字节扇区为单位的最大大小请求。
		max_sectors 和 max_hw_sectors 的默认值均为 255。max_sectors 的上限为 1024。
	blk_queue_max_phys_segments(q, max_segments)
		在请求中可以处理的最大物理段数。默认值为 128（驱动程序限制）。（见 3.2.2）
	blk_queue_max_hw_segments(q, max_segments)
		硬件在请求中可以处理的最大 DMA 段数。默认值为 128（主机适配器限制，经过 DMA 重新映射后）。（见 3.2.2）
	blk_queue_max_segment_size(q, max_seg_size)
		集群段的最大大小，默认值为 64kB。
	blk_queue_hardsect_size(q, hardsect_size)
		硬件可以操作的最低可能扇区大小，默认值为 512 字节。
```

新的队列标志：

	QUEUE_FLAG_CLUSTER（见 3.2.2）

	QUEUE_FLAG_QUEUED（见 3.2.4）

ii. 高内存 I/O 功能现在被视为默认功能

2.4 中存在的通用反弹缓冲区逻辑，其中块层通常会将高内存缓冲区上的 I/O 请求复制到低内存缓冲区，假设驱动程序无法直接处理它，在 2.5 中已发生变化。反弹逻辑现在仅应用于设备无法处理 I/O 的内存范围。驱动程序可以通过为设备的请求队列设置队列反弹限制（blk_queue_bounce_limit()）来指定此功能。这避免了在设备能够处理高内存 I/O 的情况下进行复制的低效性。

为了在设备能够支持的情况下启用高内存 I/O，PCI DMA 映射例程和相关数据结构现在已被修改，以实现直接的页 -> 总线转换，而不需要虚拟地址映射（与早期的虚拟地址 -> 总线转换方案不同）。因此，这对于高内存页（没有相应的内核虚拟地址空间映射）和低内存页都能统一工作。

注意：请参阅 Documentation/DMA-API-HOWTO.txt 以讨论 PCI 高内存 DMA 方面以及分散聚集列表的映射，以及对 64 位 PCI 的支持。

仅在 I/O 需要在设备支持范围之外的物理内存地址的页面上发生的情况下，才需要特殊处理。在这些情况下，使用代表支持内存范围中的缓冲区的反弹 bio 来执行 I/O，并根据操作类型进行必要的复制输入/复制输出。例如，在读取操作的情况下，读取的数据必须在 I/O 完成时复制到原始缓冲区，因此设置了一个回调例程来执行此操作，而对于写入，在发出操作之前，数据从原始缓冲区复制到反弹缓冲区。由于原始缓冲区可能位于内核虚拟地址空间未映射的高内存区域，因此可能需要进行`kmap`操作来执行复制，并且在完成路径中可能需要特别注意，因为它可能不在中断上下文。在分配回退缓冲区时也需要特别注意（通过`GFP`标志），以避免某些高内存死锁的可能性。

也有可能从内核虚拟地址空间未映射但设备可以直接使用的高内存区域分配回退缓冲区；因此，在复制操作期间可能需要对回退页进行`kmap`。[注意：尽管在当前实现中并非如此]

在某些情况下，即使不需要回退缓冲区，也可能需要对来自高内存的页进行`kmap`。例如，设备可能需要中止 DMA 操作并恢复为 PIO 进行传输，在这种情况下，需要对页进行虚拟映射。对于 SCSI，在某些情况下也会这样做，因为低级驱动程序不能被信任能够正确处理单个`sg`条目。驱动程序应在需要时使用`__bio_kmap_atomic`和`bio_kmap_irq`例程进行`kmaps`。如果需要，驱动程序也可以使用`blk_queue_bounce()`例程将高内存 I/O 反弹到低内存以进行特定请求。

iii. 可以根据需要替换/设置 I/O 调度程序算法

与 2.4 一样，可以为特定队列插入全新的 I/O 调度程序，或从（复制）现有通用调度程序中选择并替换/覆盖其某些部分。2.5 重写提供了改进的 I/O 调度程序模块化。有更多可插入的回调，例如用于初始化、添加请求、提取请求，这使得可以将特定的 I/O 调度算法方面和细节抽象到通用循环之外。这也使得可以完全将 I/O 调度程序的实现细节从块驱动程序中隐藏起来。

应使用 I/O 调度程序包装器而不是直接访问队列。请参阅第 4 节。有关详细信息，请参阅 I/O 调度程序。

## 1.2 根据高级代码功能进行调整

i. 原始 I/O 的应用程序功能

这来自一些高性能数据库/中间件的要求，其中应用程序希望根据对访问模式和 I/O 特征的理解来做出自己的 I/O 调度决策。

ii. 高性能文件系统或其他更高级内核代码的功能

文件系统等内核组件也可以做出自己的 I/O 调度决策以优化性能。日志文件系统可能需要对 I/O 排序进行一些控制。

通用块层对此有什么样的支持？

`bio`结构中的标志和`rw`字段可用于上述一些调整，例如指示 I/O 只是预读请求，或优先级设置（当前未使用）。就用户应用程序而言，它们需要通过打开标志、`ioctl`或其他某种上层机制来与块进行通信以传递此类设置的额外机制。

### 1.2.1 请求优先级/延迟

待办事项/正在讨论：

Arjan 提出的请求优先级方案允许更高级别对队列中 I/O 请求的优先级与其他挂起请求进行一些广泛的控制（高/中/低）。例如，它允许按需读取以引入可执行页的请求比队列中尚未老化太多的挂起写请求具有更高的优先级。潜在地，此优先级甚至可以以某种方式暴露给应用程序，提供更高级别的可调性。基于时间的老化避免了低优先级请求的饥饿。`bio`结构中的`bi_rw`标志字段中的一些位旨在用于此优先级信息。

## 1.3 直接访问低级设备/驱动程序功能（旁路模式）

    （例如诊断、系统管理）

在某些情况下，高级代码需要直接访问低级设备功能，或需要能够绕过一些中间 I/O 层向设备发出命令。这些可能是通过`ioctl`接口发出的特殊控制命令，也可能是对驱动器的某些适应性测试的能力进行压力测试的原始读/写命令。在多个级别具有直接接口而无需通过上层，使得可以从介质开始逐层对 I/O 路径进行自下而上的验证。

可以绕过正常的 I/O 提交接口，例如`submit_bio`，用于此类`ioctl`或诊断接口通常使用的特别定制的请求，并且可以使用电梯`add_request`例程直接将此类请求插入队列，或者最好使用`blk_do_rq`例程将请求放在队列上并等待完成。或者，有时调用者可能只是将请求作为参数调用低级驱动程序特定的接口。

如果请求是用于传递与命令相关的特殊信息的手段，那么此类信息与`request->special`字段相关联（而不是滥用`request->buffer`字段，该字段用于请求数据缓冲区的虚拟映射）。

对于传递请求数据，如果底层驱动程序解释`bio`段或使用块层`end*request*`函数进行 I/O 完成，则调用者必须构建一个`bio`描述符来表示相关的内存缓冲区。或者，调用者可以直接使用`request->buffer`字段来指定缓冲区的虚拟地址，如果驱动程序期望以这种方式传递缓冲区地址并忽略所涉及的请求类型的`bio`条目。在后一种情况下，驱动程序将修改和管理`request->buffer`、`request->sector`和`request->nr_sectors`或`request->current_nr_sectors`字段，而不是使用块层`end_request`或`end_that_request_first`完成接口。（有关请求结构字段的简要说明，请参阅 2.3 或`Documentation/block/request.txt`）

[待办事项：即使在这种情况下也应该可以使用`end_that_request_last`；也许可以实现一个`end_that_direct_request_first`例程，以使此类驱动程序更容易处理直接请求；对于期望`bios`的驱动程序，也可以提供一个帮助函数来设置与数据缓冲区对应的`bio`]

<JENS：我不理解上述内容，为什么`end_that_request_first()`不可用？或者`_last`也是如此。我一定遗漏了一些东西>

<SUP：我在这里的意思是，如果请求没有`bio`，那么`end_that_request_first`不会修改`nr_sectors`或`current_nr_sectors`，因此不能用于在部分传输完成时推进请求状态设置。驱动程序必须手动直接修改这些字段。这是因为`end_that_request_first`仅迭代`bio`列表，并且如果请求没有与之关联的`bio`，则始终返回 0。`_last`在这种情况下可以正常工作，并且不是问题，正如我之前提到的>

### 1.3.1 预构建命令

可以创建一个带有预构建自定义命令的请求，以直接发送到设备。请求结构中的`cmd`块有空间用于填充命令字节。（即`rq->cmd`现在的大小为 16 字节，用于命令预构建，并且请求的类型现在通过`rq->flags`而不是`rq->cmd`指示）

可以设置请求结构标志来指示此类情况下的请求类型（`REQ_PC`：直接传递给驱动程序的数据包命令，`REQ_BLOCK_PC`：通过`blk_do_rq`发出的数据包命令，`REQ_SPECIAL`：特殊请求）。

这有助于提前为请求预构建设备命令。驱动程序现在可以指定一个请求准备函数（`q->prep_rq_fn`），块层将调用该函数为给定请求预构建设备命令，或对请求执行其他准备处理。
以下是排版成 Markdown 格式并翻译成中文的内容：

这个例程由 elv_next_request() 调用，即通常在处理请求之前。（对于启用了 REQ_DONTPREP 的请求，不会调用准备函数）

**旁白**：

预先构建甚至可能更早完成，即在将请求放入队列之前，而不是在驱动程序中处理请求队列时动态构建命令，因为这可能会影响中断上下文中的延迟或总体响应能力。添加早期预先构建的一种方法是在我们无法合并请求时进行。现在在请求标志中设置 REQ_NOMERGE 以在将来跳过此请求，这意味着在将其提供给设备之前它不会更改。因此，可以在那里调用预构建器钩子。

# 2. 灵活通用但极简的 I/O 结构/描述符。

## 2.1 新结构的原因和解决的需求

在 2.5 之前，缓冲区头在通用块层被用作 I/O 的单元，并且底层请求结构与连续 I/O 请求的缓冲区头链相关联。这在处理大型 I/O 请求和 readv/writev 风格的操作时导致了某些效率低下，因为它迫使此类请求在传递到通用块层之前被分解为小块，只有在底层设备能够一次性处理 I/O 时才由 I/O 调度程序合并。此外，对于并非来自缓冲区缓存的 I/O，使用缓冲区头作为 I/O 结构不必要地增加了为每个此类块生成的描述符的权重。

在 2.5 中重新设计块 I/O 数据结构时考虑了以下一些目标和期望。

i. 应适合作为原始和缓冲 I/O 的描述符 - 避免与缓存相关的字段，这些字段在直接/页面 I/O 路径中不相关，或者文件系统块大小对齐限制可能与原始 I/O 无关。

ii. 能够表示高内存缓冲区（在内核地址空间中没有虚拟地址映射）。

iii. 能够表示大型 I/O 而无需不必要地将其分解（即一次大于 PAGE_SIZE 的块）

iv. 同时，能够保留来自不同源或需要单独完成的 I/O 单元（例如出于延迟原因）的 I/O 的独立标识。

v. 能够表示涉及多个物理内存段的 I/O（包括通过 readv/writev 指定的非页面对齐的页面片段），如果底层设备能够处理，则无需不必要地将其分解。

vi. 最好基于可以在不同类型的子系统或层（甚至网络）之间传递的内存描述符结构，在此过程中无需重复或额外复制数据/描述符字段本身。

vii. 能够以最小的开销处理结构通过分层驱动程序（lvm、md、evms）时的拆分/合并可能性。

解决方案是为块层定义一个新的结构（bio），而不是直接使用缓冲区头结构（bh），其想法是避免一些相关的包袱和限制。bio 结构在块层的所有 I/O 中统一使用；对于缓冲 I/O，它构成 bh 结构的一部分，对于原始/直接 I/O，kiobufs 映射到 bio 结构。

## 2.2 bio 结构体

bio 结构使用指向`<页，偏移量，长度>`元组数组的向量表示来描述 I/O 缓冲区，并具有描述 I/O 参数和执行 I/O 所需维护的状态的各种其他字段。

请注意，这种表示意味着 bio 根本没有虚拟地址映射（与缓冲区头不同）。 

```c
struct bio_vec {
       struct page     *bv_page;
       unsigned short  bv_len;
       unsigned short  bv_offset;
};

/*
 * main unit of I/O for the block layer and lower layers (ie drivers)
 */
struct bio {
       struct bio          *bi_next;    /* request queue link */
       struct block_device *bi_bdev;	/* target device */
       unsigned long       bi_flags;    /* status, command, etc */
       unsigned long       bi_rw;       /* low bits: r/w, high: priority */

       unsigned int	bi_vcnt;     /* how may bio_vec's */
       struct bvec_iter	bi_iter;	/* current index into bio_vec array */

       unsigned int	bi_size;     /* total size in bytes */
       unsigned short 	bi_phys_segments; /* segments after physaddr coalesce*/
       unsigned short	bi_hw_segments; /* segments after DMA remapping */
       unsigned int	bi_max;	     /* max bio_vecs we can hold
                                        used as index into pool */
       struct bio_vec   *bi_io_vec;  /* the actual vec list */
       bio_end_io_t	*bi_end_io;  /* bi_end_io (bio) */
       atomic_t		bi_cnt;	     /* pin count: free when it hits zero */
       void             *bi_private;
};
```

采用这种多页 bio 设计：

- 大型的 I/O 可以一次性发送，使用由`<页，偏移量，长度>`片段组成的 bio_vec 列表（类似于零拷贝网络代码中片段的表示方式）

- 跨多个设备拆分 I/O 请求（如在 LVM 或 RAID 的情况下）是通过克隆 bio 来实现的（其中克隆指向相同的 bi_io_vec 数组，但索引和大小相应地修改）

- 不相关的合并仍然像以前一样使用 bio 的链表（*） - 这避免了重新分配，并使独立完成更容易处理。

- 遍历请求列表的代码可以通过使用 rq_for_each_segment 找到 bio 的所有段。这处理了一个请求具有多个 bio，每个 bio 可以有多个段的情况。

- 不能一次性处理大型 bio 的驱动程序可以使用 bi_iter 字段来跟踪要处理的下一个 bio_vec 条目。（例如，对于 IDE，1MB 的 bio_vec 需要以最大 128kB 的块来处理）

  [待定：最好还应有 bi_voffset 和 bi_vlen 以避免修改 bi_offset 和 len 字段]

（*）不相关的合并 - 一个请求最终包含两个或更多并非来自同一来源的 bio。

bi_end_io() I/O 回调在整个 bio 的 I/O 完成时被调用。

在较低级别，驱动程序从合并的 bio 构建分散/聚集列表。分散/聚集列表的形式是一个`<页，偏移量，长度>`条目的数组，并在适当的时候填写其对应的 DMA 地址映射。作为一种优化，连续的物理页可以由单个条目覆盖，其中`<页>`指的是第一页，`<长度>`覆盖页的范围（最多可以用这种方式覆盖 16 个连续的页）。有一个辅助例程（blk_rq_map_sg），驱动程序可以使用它来构建 sg 列表。

注意：目前，唯一使用具有多于一页的 bio 的是 ll_rw_kio，这意味着只有原始 I/O 使用它（直接 I/O 可能现在无法正常工作）。然而，目的是使页面聚类等成为可能。来自 SGI 的 pagebuf 抽象层也使用多页 bio，但目前未包含在标准开发内核中。Andrew Morton 正在进行的多页 bio 写入和预读补丁也是如此。

## 2.3 请求结构中的更改

请求结构是传递给底层驱动程序的结构。块层的 make_request 函数构建请求结构，将其放入队列中，并调用驱动程序的 request_fn。驱动程序使用块层的辅助例程 elv_next_request 从队列中取出下一个请求。控制或诊断功能可能绕过块层并直接调用底层驱动程序的入口点，传递一个专门构建的 
request structure.只有一些相关字段（主要是那些在此处的讨论中发生变化或可能被提及的字段）列在下面，不一定按照它们在结构中出现的顺序（请参阅 include/linux/blkdev.h）。有关所有请求结构字段的详细信息以及应该使用或修改这些字段的层的快速参考，请参考 Documentation/block/request.txt。

```c
struct request {
    struct list_head queuelist;  /* 不打算由驱动程序直接访问。
                                    由 q->elv_next_request_fn 使用
                                    rq->queue 已不存在
                                    */
   .
   .
    unsigned char cmd[16]; /* 预构建的命令数据块 */
    unsigned long flags;   /* 也包括早期的 rq->cmd 设置 */
   .
   .
    sector_t sector; /* 此字段现在是 sector_t 类型，而不是 int 类型，
                        为 64 位扇区做准备 */
   .
   .
    /* 在执行物理地址合并后，分散 - 聚集 DMA 地址 + 长度对的数量 */
    unsigned short nr_phys_segments;

    /* 在执行物理和 DMA 重新映射硬件合并后，分散 - 聚集地址 + 长度对的数量。
     * 这是驱动程序在完成 DMA 映射后实际必须处理的分散 - 聚集条目数量。 */
    unsigned short nr_hw_segments;

    /* 各种扇区计数 */
    unsigned long nr_sectors;  /* 剩余扇区数：驱动程序可修改 */
    unsigned long hard_nr_sectors;  /* 上述的块内部副本 */
    unsigned int current_nr_sectors; /* 当前段中剩余的扇区数：驱动程序可修改 */
    unsigned long hard_cur_sectors; /* 上述的块内部副本 */
   .
   .
    int tag;	/* 与请求相关的命令标签 */
    void *special;  /* 与以前相同 */
    char *buffer;   /* 仅对低内存缓冲区有效，最多到 current_nr_sectors */
   .
   .
    struct bio *bio, *biotail;  /* 生物列表而不是 bh */
    struct request_list *rl;
}
```

有关各种标志的解释，请参阅 rq_flag_bits 定义。一些位由块层或 I/O 调度程序使用。

各种扇区计数的行为与以前几乎相同，除了由于我们有多段 bio，current_nr_sectors 指的是正在处理的当前段中的扇区数，这可能是当前 bio（即 I/O 完成单元）中的许多段之一。nr_sectors 值指的是整个请求中仍需传输的扇区总数（没有变化）。hard_xxx 值的目的是让块每次将请求移交给驱动程序时都记住这些计数。这些值在 end_that_request_first 时由块更新，即每次驱动程序完成一部分传输并调用块 end*request 辅助函数来标记此情况时。驱动程序不应修改这些值。块层根据相应的 hard_xxx 值和传输的字节数设置 nr_sectors 和 current_nr_sectors 字段，并在每次调用 end_that_request_first 的传输时更新它。它对 buffer、bio、bio->bi_iter 字段也做同样的事情。

buffer 字段只是 I/O 缓冲区当前段的虚拟地址映射，在缓冲区位于低内存的情况下。对于高内存 I/O，此字段无效，驱动程序不得使用。

设置自己的请求结构并将其传递给驱动程序的代码需要注意与驱动程序使用的块层辅助函数的互操作性（第 1.3 节）。

# 3. 使用 bio

## 3.1 设置/拆卸

有用于管理 bio（bio_alloc、bio_get、bio_put）的分配、引用计数和释放的例程。

这利用了 Ingo Molnar 的内存池实现，该实现使 bio 等子系统能够维护自己的保留内存池，以在极端 VM 负载期间保证无死锁分配。例如，VM 子系统利用块层来写出脏页，以便能够释放内存空间，这是一个需要仔细处理的情况。在无法通过正常方式分配的情况下，分配逻辑会从预分配的紧急储备中获取。如果池为空并且可以等待，那么它将触发有助于释放内存或补充池（不会死锁）并等待池中的可用性的操作。如果在 IRQ 上下文中，因此无法执行此操作，并且池为空，则分配可能会失败。一般来说，内存池总是首先尝试在不必等待的情况下进行分配，即使这意味着深入到池中，只要它不低于 50％满。

在释放时，根据池中的当前可用性，内存将释放回池或直接释放。内存池接口允许子系统指定用于正常分配和释放的例程。对于 bio，这些例程使用标准的 slab 分配器。

bio_alloc 的调用者应该采取某些步骤来避免死锁，例如避免在已经持有从池中获得的内存时尝试从池中分配更多内存。[待办事项：这是一个潜在问题，尽管在当前代码中发生的反弹 bio 分配中这种可能性很小，因为它最终会在持有原始 bio 的同时从同一池中分配第二个 bio]

从池中分配的内存应在有限的时间内释放回池中（对于 bio，即在 I/O 完成后）。这确保如果池的一部分已被使用，某些工作（在这种情况下为 I/O）必须已经在进行中，并且在结束时内存将可用。如果在同一代码路径中从多个池分配，分配的顺序或层次结构需要一致，就像处理多个锁一样。

bio_alloc 例程还需要为非克隆 bio 分配 bio_vec_list（bvec_alloc()）。为不同大小的 biovec 设置了 6 个池，因此 bio_alloc(gfp_mask, nr_iovecs) 将从这些 slab 中分配给定大小的 vec_list。

bio_get()例程可用于在提交 I/O 之前持有 bio 的额外引用，如果在发出 I/O 后可能会访问 bio 字段（因为如果在此期间发生 I/O 完成，bio 可能会被释放）。

bio_clone()例程可用于复制 bio，其中克隆与原始 bio 共享 bio_vec_list（即两者都指向相同的 bio_vec_list）。这通常用于在 lvm 或 md 中拆分 I/O 请求。

## 3.2 通用 bio 辅助例程

### 3.2.1 遍历请求中的段和完成单元

应使用宏 rq_for_each_segment()来遍历请求列表中的 bio（驱动程序应避免直接尝试自己执行此操作）。使用这些辅助函数还应使将来更容易应对块更改。

```c
struct req_iterator iter;
rq_for_each_segment(bio_vec, rq, iter)
    /* bio_vec 现在是当前段 */
```

I/O 完成回调是每个 bio 而不是每个段，因此在完成时遍历 bio 链的驱动程序需要牢记这一点。不需要区分段和完成单元的驱动程序需要进行重组以支持多段 bio。

### 3.2.2 设置 DMA 分散列表

blk_rq_map_sg()辅助例程将用于从请求中设置分散 - 聚集列表，因此驱动程序无需自行执行此操作。

```c
nr_segments = blk_rq_map_sg(q, rq, scatterlist);
```

该辅助例程提供了一定程度的抽象，使得在不破坏驱动程序的情况下更容易修改请求到分散列表转换的内部结构。blk_rq_map_sg 例程处理了一些事情，例如合并物理连续的段（如果设置了 QUEUE_FLAG_CLUSTER）和正确的段计数，以避免超过 I/O 硬件可以处理的限制，这取决于各种队列属性。- 防止集群段跨越 4GB 内存边界

- 避免构建超出驱动程序可以处理的物理内存段数量（`phys_segments`）和底层硬件一次可以处理的数量（考虑 DMA 重新映射（`hw_segments`），即 IOMMU 感知限制）的段。

低级驱动程序可以用于设置段限制的例程：

`blk_queue_max_hw_segments()`：设置请求中硬件数据段的最大数量上限（即主机适配器一次实际可以交给设备的地址/长度对的最大数量）

`blk_queue_max_phys_segments()`：设置请求中物理数据段的最大数量上限（即驱动程序可以处理的最大大小的分散列表）

### 3.2.3 I/O 完成

现有的通用块层辅助例程`end_request`、`end_that_request_first`和`end_that_request_last`可以像以前一样用于 I/O 完成（并设置好以便可以启动其余的 I/O 或下一个请求）。随着多页`bio`支持的引入，`end_that_request_first`需要一个额外的参数来指示完成的扇区数量。

### 3.2.4 对不解释`bios`（不处理多个段）的驱动程序的影响

不解释`bios`的驱动程序，例如不处理多个段且不支持向高内存地址进行 I/O（需要回写缓冲区）并仅期望虚拟映射缓冲区的驱动程序，可以访问`rq->buffer`字段。像以前一样，驱动程序应该使用`current_nr_sectors`来确定当前段中剩余数据的大小（即除非它解释段，否则一次可以传输的最大值），并依赖块层的`end_request`或`end_that_request_first/last`在传输完成时处理下一个`bio`段的所有记账和透明映射。（仅当请求来自块/`bio`路径时才应使用`end*request*`函数，而对于仅指定`rq->buffer`而没有有效`rq->bio`的直接访问请求则不应使用）

### 3.2.5 通用请求命令标记

#### 3.2.5.1 标记辅助函数

块现在提供一些简单的通用功能来帮助支持命令队列（通常称为标记命令队列），即在任何给定时间在队列上管理多个未完成的命令。

`blk_queue_init_tags(struct request_queue *q, int depth)`

为最大深度为`depth`初始化内部命令标记结构。

`blk_queue_free_tags((struct request_queue *q)`

拆除与队列相关的标记信息。如果在使用标记的队列上调用`blk_queue_cleanup()`，块将自动执行此操作。

上述是初始化和退出管理，在正常操作期间的主要辅助函数是：

`blk_queue_start_tag(struct request_queue *q, struct request *rq)`

为这个请求启动标记操作。为请求分配一个介于 0 和`depth`之间的空闲标记号（`rq->tag`保存此编号），并将`rq`添加到内部标记管理中。如果此队列的最大深度已经达到（或者由于其他原因未启动标记），则返回 1。否则返回 0。

`blk_queue_end_tag(struct request_queue *q, struct request *rq)`

在此请求上结束标记操作。从内部记账结构中删除`rq`。

为了最小化`struct request`和队列开销，标记辅助函数利用了一些用于正常请求队列管理的相同请求成员。这意味着请求不能同时是活动标记并且在队列列表中。`blk_queue_start_tag()`将删除请求，但驱动程序必须记住在向块层指示请求完成之前调用`blk_queue_end_tag()`。这意味着在调用`end_that_request_last()`之前结束标记操作！有关这些辅助函数的用户示例，请参阅 IDE 标记命令队列支持。

某些硬件条件可能需要使块标记队列无效。例如，在 IDE 上，任何标记请求错误都需要清除硬件和软件块队列，并使驱动程序能够合理地重新启动所有未完成的请求。有第三个辅助函数可以执行此操作：

`blk_queue_invalidate_tags(struct request_queue *q)`

清除内部块标记队列并将所有挂起的请求重新添加到请求队列中。驱动程序将在下次`request_fn`运行时再次收到它们，就像它第一次遇到它们时一样。

#### 3.2.5.2 标记信息

存在一些块函数来查询当前标记状态或从标记号转到相关请求。这些函数的顺序不固定：

`blk_queue_tagged(q)`

如果队列`q`正在使用标记，则返回 1，否则返回 0。

`blk_queue_tag_request(q, tag)`

返回与标记`tag`相关的请求的指针。

`blk_queue_tag_depth(q)`

返回当前队列深度。

`blk_queue_tag_queue(q)`

如果队列可以接受新的排队命令，则返回 1，否则如果我们已经达到最大深度，则返回 0。

`blk_queue_rq_tagged(rq)`

如果请求`rq`已标记，则返回 1。

#### 3.2.5.2 内部结构

在内部，块在`blk_queue_tag`结构中管理标记：

`struct blk_queue_tag {

    struct request **tag_index;  /* 指向 rq 的指针数组 */

    unsigned long *tag_map;  /* 空闲标记的位图 */

    struct list_head busy_list;  /* 繁忙标记的 FIFO 列表 */

    int busy;  /* 队列深度 */

    int max_depth;  /* 最大队列深度 */

};`

上述大部分内容简单明了，但是`busy_list`可能需要一些解释。通常我们不太关心请求的顺序，但是在标记队列中存在任何屏障请求的情况下，我们需要确保请求以它们被排队的顺序重新启动。这可能会在驱动程序需要使用`blk_queue_invalidate_tags()`时发生。

## 3.3 I/O 提交

`submit_bio()`例程用于提交单个 I/O。更高级别的 I/O 例程使用此例程：

(a) 缓冲 I/O：

`submit_bh()`例程在与`bh`对应的`bio`上调用`submit_bio()`，如果需要则分配`bio`。`ll_rw_block()`像以前一样使用`submit_bh()`。

(b) Kiobuf I/O（用于原始/直接 I/O）：

`ll_rw_kio()`例程将`kiobuf`分解为页大小的块，并将数组映射到一个或多个多页`bio`，对每个`bio`发出`submit_bio()`以执行 I/O。

`kiobuf`结构中的嵌入式`bh`数组已被删除，并且不为`kiobuf`预分配`bio`。[目的是也删除`blocks`数组，但目前它在那里是为了解决直接 I/O 的问题。]

因此，`kiobuf`分配已切换回使用`kmalloc`而不是`vmalloc`。

待办事项/观察：

假设单个`kiobuf`结构对应于连续的数据范围，因此`brw_kiovec()`为`kiovec`中的每个`kiobuf`调用`ll_rw_kio`。所以目前它不适用于非连续块上的直接 I/O。这将得到解决。最终的方向是用`kvec`替换`kiobuf`。

Badari Pulavarty 有一个补丁可以使用`bio`和`kvec`正确实现直接 I/O。

(c) 页 I/O：

待办事项/正在讨论：

Andrew Morton 的多页`bio`补丁试图从页缓存中发出多页写出（和读取），通过直接构建大型`bio`进行提交，完全绕过缓冲区头的使用。这项工作仍在进行中。

Christoph Hellwig 有一些使用`bio`进行页 I/O 的代码（而不是`bh`）。这尚未包含在`bio`中。Christoph 还在设计一种将虚拟/实际范围表示为一个实体并修改一些地址空间操作接口以利用此抽象而不是缓冲区头的方法。（这在某种程度上类似于 SGI XFS 页缓冲区抽象，但旨在尽可能轻量级）。(d) 直接访问 I/O：

不包含 bios 的直接访问请求将以不同的方式提交，如 1.3 节前面所讨论的那样。

旁注：

Kvec I/O：

Ben LaHaise 的 aio 代码使用一种稍微不同的结构来代替 kiobufs，称为 kvec_cb。它包含一个由<页，偏移量，长度>元组组成的数组（非常类似于网络代码），以及一个回调函数和数据指针。当传递给 brw_kvec_async()时，它被嵌入到 brw_cb 结构中。

现在应该可以将这些 kvec 直接映射到一个 bio 中。就像在克隆时一样，在这种情况下，不是 PRE_BUILT 的 bio_vecs，我们将 bi_io_vec 数组指针设置为指向 kvecs 中的 veclet 数组。

待办事项：为了使这起作用，今天处理多页 bios 的方式需要进行一些更改。从更高层代码传入的这样一个向量中的元组值不应在块层的请求处理过程中被修改，因为这将使更高层在 I/O 完成后难以继续使用向量描述符（kvec）。相反，所有这样的临时状态应该要么在请求结构中维护，并以某种方式传递给 endio 完成例程。

# 4. I/O 调度程序

I/O 调度程序，又称电梯，在两层中实现。通用调度队列和特定的 I/O 调度程序。除非另有说明，电梯用于指代这两部分，I/O 调度程序用于特定的 I/O 调度程序。

块层在 block/*.c 中实现通用调度队列。通用调度队列负责重新排队、处理非文件系统请求和所有其他细节。

特定的 I/O 调度程序负责对正常文件系统请求进行排序。它们还可以选择延迟某些请求以提高吞吐量或其他目的。正如复数形式所示，有多个 I/O 调度程序。它们可以作为模块构建，但至少应该有一个在内核中构建。每个队列可以选择不同的一个，也可以动态地更改为另一个。

块层对 I/O 调度程序的调用遵循 elv_xxx()的约定。这在电梯开关（block/elevator.c）中调用 elevator_xxx_fn。哦，xxx 和 xxx 可能不完全匹配，但请发挥你的想象力。如果电梯没有实现一个函数，开关将不执行任何操作或执行一些最小的内务处理工作。

## 4.1. I/O 调度程序 API

电梯可能实现的函数是：（*是必需的）

```
elevator_merge_fn		被调用以查询请求与一个 bio 的合并
elevator_merge_req_fn		当两个请求被合并时被调用。被合并到另一个请求中的那个请求将不再被 I/O 调度程序看到。换句话说，合并后，请求就消失了。
elevator_merged_fn		当调度程序中的一个请求参与合并时被调用。例如，在 deadline 调度程序中，它用于在排序顺序改变时重新定位请求。
elevator_allow_merge_fn		每当块层确定一个 bio 可以安全地合并到现有的请求中时被调用。I/O 调度程序在此时仍可能希望停止合并，如果它在内部导致某种冲突，此钩子允许它这样做。然而，请注意，两个*请求*仍然可以在稍后合并。目前，I/O 调度程序没有办法阻止这种情况。它只能从 elevator_merge_req_fn 回调中了解到这个事实。
elevator_dispatch_fn*		用准备好的请求填充调度队列。I/O 调度程序可以通过不填充调度队列（除非@force 非零）来推迟请求。一旦调度，I/O 调度程序不允许操作请求 - 它们属于通用调度队列。
elevator_add_req_fn*		被调用以将一个新请求添加到调度程序中
elevator_former_req_fn
elevator_latter_req_fn		这些返回在磁盘排序顺序中指定请求之前或之后的请求。由块层用于查找合并可能性。
elevator_completed_req_fn	当一个请求完成时被调用。
elevator_may_queue_fn		如果调度程序希望允许当前上下文排队一个新请求，即使它超过了队列限制，也返回 true。必须非常小心地使用此函数！！
elevator_set_req_fn
elevator_put_req_fn		必须用于为请求分配和释放任何电梯特定的存储。
elevator_activate_req_fn	当设备驱动程序首次看到一个请求时被调用。I/O 调度程序可以使用此回调来确定一个请求的实际执行何时开始。
elevator_deactivate_req_fn	当设备驱动程序通过重新排队决定延迟一个请求时被调用。
elevator_init_fn*
elevator_exit_fn		为队列分配和释放任何电梯特定的存储。
```

## 4.2 I/O 调度程序看到的请求流

I/O 调度程序看到的所有请求严格遵循以下三种流之一。

 set_req_fn ->

i.   add_req_fn -> (merged_fn ->)* -> dispatch_fn -> activate_req_fn ->

      (deactivate_req_fn -> activate_req_fn ->)* -> completed_req_fn

ii.  add_req_fn -> (merged_fn ->)* -> merge_req_fn

iii. [无]

 -> put_req_fn

## 4.3 I/O 调度程序实现

通用 I/O 调度程序算法尝试对请求进行排序/合并/批处理，以实现最佳的磁盘扫描和请求服务性能（基于通用原则和设备能力），针对以下方面进行了优化：

i. 提高吞吐量

ii. 降低延迟

iii. 更好地利用硬件和 CPU 时间

特点：

i. 二叉树

AS 和 deadline I/O 调度程序使用红黑二叉树进行磁盘位置排序和搜索，并使用先进先出链表进行基于时间的搜索。这提供了良好的可扩展性和信息的可用性。请求几乎总是按照磁盘排序顺序调度，因此会保留下一个按排序顺序的请求的缓存，以防止二叉树查找。

然而，这种安排不是通用块层的特征，因此电梯可以根据自己的意愿实现队列。

ii. 合并哈希

AS 和 deadline 使用一个由请求的最后扇区索引的哈希表。这使得合并代码能够快速查找“后合并”候选者，即使在一个磁盘上同时执行多个 I/O 流时也是如此。

“前合并”，即在现有请求的前面合并一个新请求，由于大多数 I/O 模式的性质，比“后合并”要少得多。前合并由 AS 和 deadline 调度程序中的二叉树处理。

iii. 插入队列以批量处理请求，以期待合并/排序优化的机会

插入是当前 I/O 调度算法采用的一种方法，以便它在队列中收集足够的请求，以便能够利用电梯中的排序/合并逻辑。如果在一个请求进入时队列为空，那么它会插入请求队列（有点像堵塞容器的浴缸以让流体积累），直到它再填充几个请求，然后才开始服务请求。这提供了在将请求传递给设备之前合并/排序请求的机会。有各种条件会导致队列被拔出（再次打开流量），要么通过计划任务，要么可以按需进行。例如，wait_on_buffer 通过 sync_buffer()运行 blk_run_address_space(mapping)来设置拔出。或者调用者可以通过 blk_unplug(bdev)显式地进行操作。因此，在读取情况下，队列会作为等待该缓冲区完成的一部分被显式拔出。对于页面驱动的 I/O，地址空间 ->sync_page()负责执行 blk_run_address_space()。

旁注：

这是一个有争议的领域，因为不清楚插入是否总是正确的事情。设备通常有自己的队列，允许在软件中建立一个大队列，而让设备空闲一段时间可能并不总是有意义的。技巧在于处理插入和打开之间的微妙平衡。另外，由于我们现在可以一次性排队多个页面的 bios，我们可能不需要等待将一个大请求从拆分的部分合并。

## 4.4 I/O 上下文

I/O 上下文提供了一个动态分配的每个进程的数据区域。它们可用于 I/O 调度程序和块层（例如可用于 IO 统计、优先级）。请参阅 *io_context 在 block/ll_rw_blk.c 中，以及 as-iosched.c 中 I/O 调度程序中的使用示例。

# 5. 与可伸缩性相关的更改

## 5.1 细粒度锁定：io_request_lock 被每个队列的锁替换

自 2.5 版本起，全局 io_request_lock 已被删除，以避免它导致的可伸缩性瓶颈，并已被更细粒度的锁定替换。请求队列结构有一个指向用于该队列的锁的指针。结果，现在可以按每个队列进行锁定，并在必要时提供跨队列共享锁的规定（例如，scsi 层将队列锁指针设置为相应的适配器锁，这导致每个主机的锁定粒度）。锁定语义相同，即锁定仍然由块层施加，在请求函数执行之前获取锁，这意味着许多旧驱动程序仍然应该是 SMP 安全的。如果需要，驱动程序可以自由地自己释放队列锁。明确使用 io_request_lock 进行序列化的驱动程序需要相应地进行修改。通常，这就像添加一个全局锁一样简单：

    static DEFINE_SPINLOCK(my_driver_lock);

并将该锁的地址传递给 blk_init_queue()。

## 5.2 64 位扇区编号（sector_t 为 64 位支持做准备）

bio 结构中使用的扇区编号已更改为 sector_t，它可以定义为 64 位，以准备支持 64 位扇区。

# 6. 其他更改/影响

## 6.1 分区重新映射由通用块层处理

在 2.5 版本中，一些与 gendisk/分区相关的代码已被重组。现在，通用块层早期执行分区重新映射，从而为驱动程序提供相对于整个设备的扇区编号，而不必考虑分区编号以获得真实的扇区编号。即使在调用队列特定的 make_request_fn 之前，通用_make_request 也会调用例程 blk_partition_remap()，因此 I/O 调度程序也可以对整个磁盘扇区编号进行操作。通常，这不需要对块驱动程序进行更改，因为所有 bios 都是从设备开头偏移发送的，所以它永远不会调用自己的分区扇区偏移计算。

# 7. 关于旧驱动程序迁移的一些提示

仅使用 CURRENT 且忽略集群请求的旧式驱动程序可能不需要太多更改。通用层将自动为驱动程序处理集群请求、多页面 bios 等。对于低性能驱动程序或 PIO 驱动或不支持分散/聚集更改的硬件，更改也应该很小。

将旧驱动程序转换为 bio 时，应牢记以下几点：

驱动程序应使用 elv_next_request 来获取请求，不再应直接在请求列表上处理循环。（struct request->queue 已被删除）

现在 end_that_request_first 接受一个额外的 number_of_sectors 参数。它过去总是只处理请求中的第一个 buffer_head，现在它将循环并处理指定的尽可能多的扇区（基于 bio 段粒度）。

现在 bh->b_end_io 被 bio->bi_end_io 替换，但大多数时候正确的做法是使用 bio_endio(bio, uptodate) 代替。

如果驱动程序从其 request_fn 策略中删除 io_request_lock，那么它只需要用 q->queue_lock 替换它。

如第 1.1 节所述，驱动程序现在可以为每个队列设置最大扇区大小、最大段大小等。曾经定义自己的合并函数来处理此类事情的驱动程序现在可以在 blk_init_queue 时仅使用 blk_queue_* 函数。

驱动程序不再需要将 {分区，扇区偏移} 映射到正确的绝对位置，这由块层完成，所以如果驱动程序之前以这种方式接收请求：

    rq->rq_dev = mk_kdev(3, 5);  /* /dev/hda5 */

    rq->sector = 0;  /* hda5 上的第一个扇区 */

现在它将看到

    rq->rq_dev = mk_kdev(3, 0);  /* /dev/hda */

    rq->sector = 123128;  /* 从磁盘开头的偏移量 */

如前所述，bio 没有虚拟映射。对于 DMA，这不是问题，因为驱动程序可能永远不需要虚拟映射。相反，它需要总线映射（对于单个段使用 dma_map_page 或对于分散/聚集使用 dma_map_sg）才能将其发送到驱动程序。对于 PIO 驱动程序（或偶尔需要回退到 PIO 传输的驱动程序（例如 IDE）），需要虚拟映射，因为 CPU 正在执行实际的数据传输。如果驱动程序支持 highmem I/O（第 1.1 节，(ii)），它需要使用 __bio_kmap_atomic 和 bio_kmap_irq 暂时将 bio 映射到虚拟地址空间。

# 8. 先前/相关/受影响的补丁

## 8.1. 早期的 kiobuf 补丁（sct/axboe/chait/hch/mkp）

- 原始 kiobuf 和原始 I/O 补丁（现在在 2.4 树中）

- 直接基于 kiobuf 的设备 I/O（没有中间的 bh）

- 使用 kiobuf 的页面 I/O

- 用于 LVM 的 kiobuf 拆分（mkp）

- 用于 kiobuf 请求合并的电梯支持（axboe）

## 8.2. 零拷贝网络（Dave Miller）

## 8.3. SGI XFS - 页面缓冲区补丁 - 使用 kiobufs

## 8.4. 用于 bio 的多页面 pioent 补丁（Christoph Hellwig）

## 8.5. 直接 I/O 实现（Andrea Arcangeli）自 2.4.10-pre11 起

## 8.6. 异步 I/O 实现补丁（Ben LaHaise）

## 8.7. EVMS 分层设计（IBM EVMS 团队）

## 8.8. 更大的页面缓存大小补丁（Ben LaHaise）和

    大页面大小（Daniel Phillips）

    => 更大的连续物理内存缓冲区

## 8.9. VM 预留补丁（Ben LaHaise）

## 8.10. 写入集群补丁？（Marcelo/Quintela/Riel？）

## 8.11. 页缓存中的块设备补丁（Andrea Archangeli） - 现在在 2.4.10+ 中

## 8.12. 用于更快原始 I/O 的多块大小传输（Shailabh Nagar，Badari）

## 8.13 基于优先级的 I/O 调度程序 - 预补丁（Arjan van de Ven）

## 8.14 IDE 任务文件 I/O 补丁（Andre Hedrick）

## 8.15 多页面写出和预读补丁（Andrew Morton）

## 8.16 用于 2.5 的使用 kvec 和 bio 的直接 I/O 补丁（Badari Pulavarthy）

# 9. 其他参考：

## 9.1 拼接 I/O 模型 - Larry McVoy（以及随后在 lkml 上的讨论，以及 Linus 的评论 - 2001 年 1 月）

## 9.2 关于 lkml 上 kiobuf 和 bh 设计的讨论，sct、linus、alan 等人之间 - 2001 年 2 月至 3 月（导致 bio 的许多最初想法都在这个讨论线程中提出）

## 9.3 关于 lkml 上内存池的讨论 - 2001 年 12 月。